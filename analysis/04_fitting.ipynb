{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    }
   ],
   "source": [
    "from scipy import io\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "# rng = np.random.default_rng()\n",
    "\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "\n",
    "import optax\n",
    "\n",
    "from collections import defaultdict\n",
    "import pickle as pkl\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from dynamax.hidden_markov_model import ET_HMM, E_HMM, T_HMM\n",
    "from dynamax.utils.plotting import gradient_cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((260, 120, 4), (260, 120, 1))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load calibrated design matrix and observation\n",
    "# design matrix:\n",
    "#   - 1st column: Stimulus (calibrated)\n",
    "#   - 2nd column: Coherence\n",
    "#   - 3rd column: Attention\n",
    "#   - 4th column: Expectation (calibrated)\n",
    "design_matrix = np.load(\"../analysis/cache/exp_design.npy\")\n",
    "observation = np.load(\"../analysis/cache/exp_obs.npy\")\n",
    "\n",
    "design_matrix.shape, observation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to radians\n",
    "design_matrix[:,:,0] = np.deg2rad(design_matrix[:,:,0])\n",
    "design_matrix[:,:,3] = np.deg2rad(design_matrix[:,:,3])\n",
    "\n",
    "observation = np.deg2rad(observation)\n",
    "\n",
    "# Add flat biases column\n",
    "flat_biases = np.ones_like(design_matrix[:,:,:1])\n",
    "design_matrix =  np.concatenate([design_matrix, flat_biases], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle data\n",
    "shuff_idx = np.random.permutation(len(design_matrix))\n",
    "\n",
    "design_matrix = design_matrix[shuff_idx]\n",
    "observation = observation[shuff_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split it 80:20 for training and testing\n",
    "\n",
    "train_idx = int(0.8 * len(design_matrix))\n",
    "\n",
    "train_design = design_matrix[:train_idx]\n",
    "train_obs = observation[:train_idx]\n",
    "\n",
    "test_design = design_matrix[train_idx:]\n",
    "test_obs = observation[train_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to jax arrays\n",
    "train_emissions = jnp.array(train_obs)\n",
    "train_inputs = jnp.array(train_design)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A training cache to store all the models and their parameters\n",
    "training_cache = defaultdict(dict)\n",
    "\n",
    "# DS to store the models organized\n",
    "class Model_Store:\n",
    "    n_states: int\n",
    "    fit_model: None\n",
    "    fit_params: None\n",
    "    lps: None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_hmms(model_class, num_states, emission_dim, input_dim, train_emissions, train_inputs):\n",
    "    \n",
    "    model = model_class(num_states, input_dim, emission_dim)\n",
    "    parameters, properties = model.initialize(key=jr.PRNGKey(1))\n",
    "\n",
    "    # Fit with SGD\n",
    "    fit_params, lps = model.fit_sgd(params = parameters, \n",
    "                                    props = properties, \n",
    "                                    emissions = train_emissions, \n",
    "                                    inputs = train_inputs, \n",
    "                                    num_epochs = 5000, \n",
    "                                    optimizer = optax.adam(1e-4), \n",
    "                                    shuffle = False, \n",
    "                                    batch_size = 32)\n",
    "    \n",
    "    return model, fit_params, lps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(10):\n",
    "#     model, fit_params, lps = train_hmms(E_HMM, 2, 1, 5, train_emissions, train_inputs)\n",
    "#     print(f\"Model {i} trained - {lps[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: ET_HMM - 2 states\n",
      "[1.9862871 1.9824057 1.9785368 1.9746825 1.9708424 1.9670181 1.9632099\n",
      " 1.9594175 1.9556417 1.9518824]\n",
      "Training: ET_HMM - 3 states\n",
      "[1.9957613 1.9918696 1.98799   1.9841245 1.9802731 1.9764369 1.9726163\n",
      " 1.9688113 1.9650222 1.9612494]\n",
      "Training: ET_HMM - 4 states\n",
      "[1.9962769 1.9923809 1.9884971 1.9846271 1.9807719 1.9769317 1.973107\n",
      " 1.9692982 1.9655054 1.9617283]\n",
      "Training: ET_HMM - 5 states\n",
      "[1.9953004 1.9914081 1.9875284 1.9836622 1.9798106 1.9759741 1.9721533\n",
      " 1.9683479 1.964559  1.9607859]\n",
      "Training: ET_HMM - 6 states\n",
      "[1.9969393 1.9930414 1.989156  1.9852844 1.9814271 1.9775847 1.9737579\n",
      " 1.969947  1.9661516 1.9623725]\n",
      "Training: E_HMM - 2 states\n",
      "[1.9859469 1.9820644 1.9781945 1.9743389 1.970498  1.9666725 1.9628631\n",
      " 1.95907   1.955293  1.9515327]\n",
      "Training: E_HMM - 3 states\n",
      "[1.994876  1.9909754 1.9870872 1.9832131 1.9793533 1.9755088 1.9716797\n",
      " 1.9678665 1.9640694 1.9602884]\n",
      "Training: E_HMM - 4 states\n",
      "[1.9923513 1.9884495 1.9845606 1.9806852 1.9768249 1.9729798 1.9691504\n",
      " 1.9653372 1.96154   1.957759 ]\n",
      "Training: E_HMM - 5 states\n",
      "[1.9934614 1.9895662 1.9856837 1.9818151 1.977961  1.9741222 1.9702986\n",
      " 1.9664915 1.9627    1.9589249]\n",
      "Training: E_HMM - 6 states\n",
      "[1.9942696 1.9903662 1.9864758 1.9825987 1.9787368 1.9748892 1.9710577\n",
      " 1.9672421 1.9634424 1.9596586]\n",
      "Training: T_HMM - 2 states\n",
      "[1.9940063 1.9930128 1.9920224 1.9910356 1.9900526 1.9890732 1.9880981\n",
      " 1.987127  1.9861596 1.9851965]\n",
      "Training: T_HMM - 3 states\n",
      "[1.9990797 1.9980785 1.9970807 1.9960861 1.9950955 1.9941086 1.993126\n",
      " 1.9921472 1.9911726 1.9902017]\n",
      "Training: T_HMM - 4 states\n",
      "[1.9972824 1.9962834 1.9952877 1.9942955 1.9933071 1.9923226 1.9913422\n",
      " 1.9903654 1.9893931 1.9884243]\n",
      "Training: T_HMM - 5 states\n",
      "[1.9931532 1.99216   1.9911696 1.990183  1.9892    1.9882209 1.9872458\n",
      " 1.9862747 1.9853075 1.9843442]\n",
      "Training: T_HMM - 6 states\n",
      "[1.9956143 1.9946165 1.9936218 1.9926306 1.9916432 1.9906596 1.98968\n",
      " 1.9887043 1.9877328 1.9867651]\n"
     ]
    }
   ],
   "source": [
    "min_state, max_state = 2, 6\n",
    "emission_dim, input_dim = 1, 5\n",
    "\n",
    "for model_class in [ET_HMM, E_HMM, T_HMM]:\n",
    "\n",
    "    for num_states in range(min_state, max_state+1):\n",
    "        print(f'Training: {model_class.__name__} - {num_states} states')\n",
    "\n",
    "        model, fit_params, lps = train_hmms(model_class, num_states, emission_dim, input_dim, train_emissions, train_inputs)\n",
    "\n",
    "        print(f\"{lps[:10]}\")\n",
    "\n",
    "        t_store = Model_Store()\n",
    "        t_store.n_states = num_states\n",
    "        t_store.fit_model = model\n",
    "        t_store.fit_params = fit_params\n",
    "        t_store.lps = lps\n",
    "\n",
    "        training_cache[model_class.__name__][num_states] = t_store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParamsET_HMM(initial=ParamsStandardHMMInitialState(probs=Array([0.65643466, 0.34356534], dtype=float32)), transitions=ParamsET_Transitions(transition_matrix=Array([[0.93811536, 0.06188458],\n",
       "       [0.94132054, 0.05867945]], dtype=float32), transition_weights=Array([[-0.00764516, -0.00025098, -0.01133804, -0.00038295, -0.00130757],\n",
       "       [-0.00110481,  0.01022496, -0.00978904,  0.00814341,  0.00280931]],      dtype=float32)), emissions=ParamsET_Emissions(weights=Array([[[ 0.216029  ,  0.02790617,  0.01633381,  0.03509545,\n",
       "          1.3987256 ]],\n",
       "\n",
       "       [[ 0.06578622, -0.02190064,  0.04457312,  0.00982139,\n",
       "          0.39937398]]], dtype=float32), covs=Array([[[ 3.292194]],\n",
       "\n",
       "       [[11.952794]]], dtype=float32)))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_cache[\"ET_HMM\"][2].fit_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_cache[\"shuffle_idx\"] = shuff_idx\n",
    "\n",
    "# # Save the trained data so we dont have to train again and again\n",
    "# with open('training_cache.pkl', 'wb') as f:\n",
    "#     pkl.dump(training_cache, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
