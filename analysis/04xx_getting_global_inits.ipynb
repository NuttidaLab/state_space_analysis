{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import io\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "# rng = np.random.default_rng()\n",
    "\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "\n",
    "import optax\n",
    "\n",
    "from collections import defaultdict\n",
    "import pickle as pkl\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from dynamax.hidden_markov_model import LinearRegressionHMM\n",
    "from dynamax.utils.plotting import gradient_cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load calibrated data\n",
    "# data:\n",
    "# final_resp_loc_jx\n",
    "# final_resp_loc_jy\n",
    "# final_resp_vel_jx\n",
    "# final_resp_vel_jy\n",
    "# final_resp_acc_jx\n",
    "# final_resp_acc_jy\n",
    "# stimulus_x\n",
    "# stimulus_y\n",
    "# coh\n",
    "# att\n",
    "\n",
    "data = np.load(\"../analysis/cache/total_data.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 13, 4, 6, 120)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13, 24, 120), (13, 24, 120))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coh = data[8].reshape(13, 24, 120)\n",
    "att = data[9].reshape(13, 24, 120)\n",
    "\n",
    "coh.shape, att.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 13, 24, 60, 4), (2, 13, 24, 60, 3))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract emissions and design matrix\n",
    "resp_x = data[0]\n",
    "resp_y = data[1]\n",
    "total_vel = np.sqrt(data[2]**2 + data[3]**2)\n",
    "total_acc = np.sqrt(data[4]**2 + data[5]**2)\n",
    "\n",
    "stim_x = data[6]\n",
    "stim_y = data[7]\n",
    "flat_biases = np.ones_like(stim_y)\n",
    "\n",
    "emissions = np.stack([resp_x, resp_y, total_vel, total_acc], axis=-1).reshape(13, 24, 120, 4)\n",
    "design_matrix = np.stack([stim_x, stim_y, flat_biases], axis=-1).reshape(13, 24, 120, 3)\n",
    "\n",
    "# separate data based on coh = 1 or coh = 0\n",
    "emissions_coh_1 = emissions[np.where(coh == 1)].reshape(13, 24, 60, 4)\n",
    "design_matrix_coh_1 = design_matrix[np.where(coh == 1)].reshape(13, 24, 60, 3)\n",
    "\n",
    "emissions_coh_0 = emissions[np.where(coh == 0)].reshape(13, 24, 60, 4)\n",
    "design_matrix_coh_0 = design_matrix[np.where(coh == 0)].reshape(13, 24, 60, 3)\n",
    "\n",
    "# Stack them at a new axis\n",
    "emissions = np.stack([emissions_coh_0, emissions_coh_1], axis=0)\n",
    "design_matrix = np.stack([design_matrix_coh_0, design_matrix_coh_1], axis=0)\n",
    "\n",
    "emissions.shape, design_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_hmms(model_class, num_states, emission_dim, input_dim, train_emissions, train_inputs):\n",
    "    \n",
    "    model = model_class(num_states, input_dim, emission_dim)\n",
    "    parameters, properties = model.initialize(key=jr.PRNGKey(1))\n",
    "\n",
    "    # Fit with SGD\n",
    "    fit_params, lps = model.fit_sgd(params = parameters, \n",
    "                                    props = properties, \n",
    "                                    emissions = train_emissions, \n",
    "                                    inputs = train_inputs, \n",
    "                                    num_epochs = 5000, \n",
    "                                    optimizer = optax.adam(1e-4), \n",
    "                                    shuffle = True, \n",
    "                                    batch_size = 8)\n",
    "    \n",
    "    return model, fit_params, lps\n",
    "\n",
    "def cross_validate(model, all_params, emissions, inputs):\n",
    "    marg_log_probs = []\n",
    "    for validation_idx in range(len(emissions)):\n",
    "        log_prob = model.marginal_log_prob(all_params, emissions[validation_idx], inputs=inputs[validation_idx])\n",
    "        marg_log_probs.append(float(log_prob))\n",
    "    return np.array(marg_log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A training cache to store all the models and their parameters\n",
    "def nested_defaultdict(): return defaultdict(nested_defaultdict)\n",
    "training_cache = nested_defaultdict()\n",
    "\n",
    "# DS to store the models organized\n",
    "class Model_Store:\n",
    "    subject_id: int\n",
    "    n_states: int\n",
    "    fit_model: None\n",
    "    fit_params: None\n",
    "    lps: None\n",
    "    valid_mllk: None\n",
    "    test_idx: None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainined: mllk - 37.832 sub - 0 LinearRegressionHMM - 2 states\n",
      "Trainined: mllk - 37.322 sub - 0 LinearRegressionHMM - 3 states\n",
      "Trainined: mllk - 52.132 sub - 0 LinearRegressionHMM - 4 states\n",
      "Trainined: mllk - 59.008 sub - 0 LinearRegressionHMM - 5 states\n",
      "Trainined: mllk - 50.015 sub - 0 LinearRegressionHMM - 6 states\n",
      "Trainined: mllk - 66.002 sub - 1 LinearRegressionHMM - 2 states\n",
      "Trainined: mllk - 40.728 sub - 1 LinearRegressionHMM - 3 states\n",
      "Trainined: mllk - 77.138 sub - 1 LinearRegressionHMM - 4 states\n",
      "Trainined: mllk - 69.787 sub - 1 LinearRegressionHMM - 5 states\n",
      "Trainined: mllk - 59.140 sub - 1 LinearRegressionHMM - 6 states\n",
      "Trainined: mllk - -21.259 sub - 2 LinearRegressionHMM - 2 states\n",
      "Trainined: mllk - -13.101 sub - 2 LinearRegressionHMM - 3 states\n",
      "Trainined: mllk - 20.074 sub - 2 LinearRegressionHMM - 4 states\n",
      "Trainined: mllk - 11.399 sub - 2 LinearRegressionHMM - 5 states\n",
      "Trainined: mllk - 33.004 sub - 2 LinearRegressionHMM - 6 states\n",
      "Trainined: mllk - 37.164 sub - 3 LinearRegressionHMM - 2 states\n",
      "Trainined: mllk - 32.837 sub - 3 LinearRegressionHMM - 3 states\n",
      "Trainined: mllk - 44.600 sub - 3 LinearRegressionHMM - 4 states\n",
      "Trainined: mllk - 46.276 sub - 3 LinearRegressionHMM - 5 states\n",
      "Trainined: mllk - 39.649 sub - 3 LinearRegressionHMM - 6 states\n",
      "Trainined: mllk - 11.097 sub - 4 LinearRegressionHMM - 2 states\n",
      "Trainined: mllk - 24.183 sub - 4 LinearRegressionHMM - 3 states\n",
      "Trainined: mllk - 33.654 sub - 4 LinearRegressionHMM - 4 states\n",
      "Trainined: mllk - 25.209 sub - 4 LinearRegressionHMM - 5 states\n",
      "Trainined: mllk - 28.384 sub - 4 LinearRegressionHMM - 6 states\n",
      "Trainined: mllk - 50.750 sub - 5 LinearRegressionHMM - 2 states\n",
      "Trainined: mllk - 36.687 sub - 5 LinearRegressionHMM - 3 states\n",
      "Trainined: mllk - 70.574 sub - 5 LinearRegressionHMM - 4 states\n",
      "Trainined: mllk - 64.944 sub - 5 LinearRegressionHMM - 5 states\n",
      "Trainined: mllk - 60.688 sub - 5 LinearRegressionHMM - 6 states\n",
      "Trainined: mllk - 55.861 sub - 6 LinearRegressionHMM - 2 states\n",
      "Trainined: mllk - 61.485 sub - 6 LinearRegressionHMM - 3 states\n",
      "Trainined: mllk - 70.498 sub - 6 LinearRegressionHMM - 4 states\n",
      "Trainined: mllk - 72.319 sub - 6 LinearRegressionHMM - 5 states\n",
      "Trainined: mllk - 58.670 sub - 6 LinearRegressionHMM - 6 states\n",
      "Trainined: mllk - 26.119 sub - 7 LinearRegressionHMM - 2 states\n",
      "Trainined: mllk - 30.301 sub - 7 LinearRegressionHMM - 3 states\n",
      "Trainined: mllk - 31.195 sub - 7 LinearRegressionHMM - 4 states\n",
      "Trainined: mllk - 42.772 sub - 7 LinearRegressionHMM - 5 states\n",
      "Trainined: mllk - 40.759 sub - 7 LinearRegressionHMM - 6 states\n",
      "Trainined: mllk - 10.544 sub - 8 LinearRegressionHMM - 2 states\n",
      "Trainined: mllk - 44.759 sub - 8 LinearRegressionHMM - 3 states\n",
      "Trainined: mllk - 54.166 sub - 8 LinearRegressionHMM - 4 states\n",
      "Trainined: mllk - 58.694 sub - 8 LinearRegressionHMM - 5 states\n",
      "Trainined: mllk - 55.017 sub - 8 LinearRegressionHMM - 6 states\n",
      "Trainined: mllk - 52.994 sub - 9 LinearRegressionHMM - 2 states\n",
      "Trainined: mllk - 53.479 sub - 9 LinearRegressionHMM - 3 states\n",
      "Trainined: mllk - 66.620 sub - 9 LinearRegressionHMM - 4 states\n",
      "Trainined: mllk - 65.421 sub - 9 LinearRegressionHMM - 5 states\n",
      "Trainined: mllk - 61.421 sub - 9 LinearRegressionHMM - 6 states\n",
      "Trainined: mllk - 34.160 sub - 10 LinearRegressionHMM - 2 states\n",
      "Trainined: mllk - 35.736 sub - 10 LinearRegressionHMM - 3 states\n",
      "Trainined: mllk - 42.749 sub - 10 LinearRegressionHMM - 4 states\n",
      "Trainined: mllk - 46.725 sub - 10 LinearRegressionHMM - 5 states\n",
      "Trainined: mllk - 36.652 sub - 10 LinearRegressionHMM - 6 states\n",
      "Trainined: mllk - 40.305 sub - 11 LinearRegressionHMM - 2 states\n",
      "Trainined: mllk - 39.090 sub - 11 LinearRegressionHMM - 3 states\n",
      "Trainined: mllk - 55.262 sub - 11 LinearRegressionHMM - 4 states\n",
      "Trainined: mllk - 52.263 sub - 11 LinearRegressionHMM - 5 states\n",
      "Trainined: mllk - 52.918 sub - 11 LinearRegressionHMM - 6 states\n",
      "Trainined: mllk - -16.121 sub - 12 LinearRegressionHMM - 2 states\n",
      "Trainined: mllk - 39.516 sub - 12 LinearRegressionHMM - 3 states\n",
      "Trainined: mllk - 44.273 sub - 12 LinearRegressionHMM - 4 states\n",
      "Trainined: mllk - 39.122 sub - 12 LinearRegressionHMM - 5 states\n",
      "Trainined: mllk - 41.523 sub - 12 LinearRegressionHMM - 6 states\n",
      "Trainined: mllk - 26.551 sub - 0 LinearRegressionHMM - 2 states\n",
      "Trainined: mllk - 22.490 sub - 0 LinearRegressionHMM - 3 states\n",
      "Trainined: mllk - 49.691 sub - 0 LinearRegressionHMM - 4 states\n",
      "Trainined: mllk - 46.791 sub - 0 LinearRegressionHMM - 5 states\n",
      "Trainined: mllk - 37.892 sub - 0 LinearRegressionHMM - 6 states\n",
      "Trainined: mllk - 86.586 sub - 1 LinearRegressionHMM - 2 states\n",
      "Trainined: mllk - 55.932 sub - 1 LinearRegressionHMM - 3 states\n",
      "Trainined: mllk - 91.986 sub - 1 LinearRegressionHMM - 4 states\n",
      "Trainined: mllk - 99.067 sub - 1 LinearRegressionHMM - 5 states\n",
      "Trainined: mllk - 76.637 sub - 1 LinearRegressionHMM - 6 states\n",
      "Trainined: mllk - 10.574 sub - 2 LinearRegressionHMM - 2 states\n",
      "Trainined: mllk - 12.858 sub - 2 LinearRegressionHMM - 3 states\n",
      "Trainined: mllk - 33.727 sub - 2 LinearRegressionHMM - 4 states\n",
      "Trainined: mllk - 34.674 sub - 2 LinearRegressionHMM - 5 states\n",
      "Trainined: mllk - 32.606 sub - 2 LinearRegressionHMM - 6 states\n",
      "Trainined: mllk - 35.782 sub - 3 LinearRegressionHMM - 2 states\n",
      "Trainined: mllk - 16.867 sub - 3 LinearRegressionHMM - 3 states\n",
      "Trainined: mllk - 40.432 sub - 3 LinearRegressionHMM - 4 states\n",
      "Trainined: mllk - 36.746 sub - 3 LinearRegressionHMM - 5 states\n",
      "Trainined: mllk - 35.096 sub - 3 LinearRegressionHMM - 6 states\n",
      "Trainined: mllk - 53.276 sub - 4 LinearRegressionHMM - 2 states\n",
      "Trainined: mllk - 31.420 sub - 4 LinearRegressionHMM - 3 states\n",
      "Trainined: mllk - 62.750 sub - 4 LinearRegressionHMM - 4 states\n",
      "Trainined: mllk - 67.364 sub - 4 LinearRegressionHMM - 5 states\n",
      "Trainined: mllk - 50.332 sub - 4 LinearRegressionHMM - 6 states\n",
      "Trainined: mllk - 87.568 sub - 5 LinearRegressionHMM - 2 states\n",
      "Trainined: mllk - 62.244 sub - 5 LinearRegressionHMM - 3 states\n",
      "Trainined: mllk - 96.281 sub - 5 LinearRegressionHMM - 4 states\n",
      "Trainined: mllk - 98.695 sub - 5 LinearRegressionHMM - 5 states\n",
      "Trainined: mllk - 87.634 sub - 5 LinearRegressionHMM - 6 states\n",
      "Trainined: mllk - 28.936 sub - 6 LinearRegressionHMM - 2 states\n",
      "Trainined: mllk - 48.949 sub - 6 LinearRegressionHMM - 3 states\n",
      "Trainined: mllk - 61.408 sub - 6 LinearRegressionHMM - 4 states\n",
      "Trainined: mllk - 63.375 sub - 6 LinearRegressionHMM - 5 states\n",
      "Trainined: mllk - 55.646 sub - 6 LinearRegressionHMM - 6 states\n",
      "Trainined: mllk - 29.105 sub - 7 LinearRegressionHMM - 2 states\n",
      "Trainined: mllk - 32.726 sub - 7 LinearRegressionHMM - 3 states\n",
      "Trainined: mllk - 38.473 sub - 7 LinearRegressionHMM - 4 states\n",
      "Trainined: mllk - 47.900 sub - 7 LinearRegressionHMM - 5 states\n",
      "Trainined: mllk - 42.500 sub - 7 LinearRegressionHMM - 6 states\n",
      "Trainined: mllk - 40.001 sub - 8 LinearRegressionHMM - 2 states\n",
      "Trainined: mllk - 47.584 sub - 8 LinearRegressionHMM - 3 states\n",
      "Trainined: mllk - 73.464 sub - 8 LinearRegressionHMM - 4 states\n",
      "Trainined: mllk - 68.304 sub - 8 LinearRegressionHMM - 5 states\n",
      "Trainined: mllk - 61.500 sub - 8 LinearRegressionHMM - 6 states\n",
      "Trainined: mllk - 76.409 sub - 9 LinearRegressionHMM - 2 states\n",
      "Trainined: mllk - 69.120 sub - 9 LinearRegressionHMM - 3 states\n",
      "Trainined: mllk - 85.700 sub - 9 LinearRegressionHMM - 4 states\n",
      "Trainined: mllk - 87.805 sub - 9 LinearRegressionHMM - 5 states\n",
      "Trainined: mllk - 79.490 sub - 9 LinearRegressionHMM - 6 states\n",
      "Trainined: mllk - 70.114 sub - 10 LinearRegressionHMM - 2 states\n",
      "Trainined: mllk - 61.083 sub - 10 LinearRegressionHMM - 3 states\n",
      "Trainined: mllk - 84.038 sub - 10 LinearRegressionHMM - 4 states\n",
      "Trainined: mllk - 91.841 sub - 10 LinearRegressionHMM - 5 states\n",
      "Trainined: mllk - 74.674 sub - 10 LinearRegressionHMM - 6 states\n",
      "Trainined: mllk - -11.628 sub - 11 LinearRegressionHMM - 2 states\n",
      "Trainined: mllk - 42.293 sub - 11 LinearRegressionHMM - 3 states\n",
      "Trainined: mllk - 43.605 sub - 11 LinearRegressionHMM - 4 states\n",
      "Trainined: mllk - 30.875 sub - 11 LinearRegressionHMM - 5 states\n",
      "Trainined: mllk - 55.009 sub - 11 LinearRegressionHMM - 6 states\n",
      "Trainined: mllk - 49.483 sub - 12 LinearRegressionHMM - 2 states\n",
      "Trainined: mllk - 47.430 sub - 12 LinearRegressionHMM - 3 states\n",
      "Trainined: mllk - 63.806 sub - 12 LinearRegressionHMM - 4 states\n",
      "Trainined: mllk - 71.777 sub - 12 LinearRegressionHMM - 5 states\n",
      "Trainined: mllk - 54.222 sub - 12 LinearRegressionHMM - 6 states\n"
     ]
    }
   ],
   "source": [
    "min_state, max_state = 2, 6\n",
    "emission_dim, input_dim = 4, 3\n",
    "\n",
    "# Training and validation loop\n",
    "for coh_idx in range(2):\n",
    "\n",
    "    for subject_idx in range(13):\n",
    "        # Split the data into training and testing randomly\n",
    "        # 4 samples for testing\n",
    "        # 20 samples for training\n",
    "        train_idx = np.random.choice(24, 20, replace=False)\n",
    "        test_idx = np.setdiff1d(np.arange(24), train_idx)\n",
    "\n",
    "        # Train data\n",
    "        train_emissions = jnp.array(emissions[coh_idx][subject_idx][train_idx])\n",
    "        train_inputs = jnp.array(design_matrix[coh_idx][subject_idx][train_idx])\n",
    "\n",
    "        # Test data\n",
    "        test_emissions = jnp.array(emissions[coh_idx][subject_idx][test_idx])\n",
    "        test_inputs = jnp.array(design_matrix[coh_idx][subject_idx][test_idx])\n",
    "\n",
    "        for model_class in [LinearRegressionHMM]:\n",
    "\n",
    "            for num_states in range(min_state, max_state+1):\n",
    "\n",
    "\n",
    "                model, fit_params, lps = train_hmms(model_class, \n",
    "                                                    num_states, \n",
    "                                                    emission_dim, \n",
    "                                                    input_dim, \n",
    "                                                    train_emissions, \n",
    "                                                    train_inputs)\n",
    "                \n",
    "                t_store = Model_Store()\n",
    "                t_store.n_states = num_states\n",
    "                t_store.fit_model = model\n",
    "                t_store.fit_params = fit_params\n",
    "                t_store.lps = lps\n",
    "                t_store.valid_mllk = cross_validate(model, fit_params, test_emissions, test_inputs)\n",
    "                t_store.test_idx = test_idx\n",
    "\n",
    "                print(f'Trainined: mllk - {t_store.valid_mllk.mean():.3f} sub - {subject_idx} {model_class.__name__} - {num_states} states')\n",
    "                \n",
    "                training_cache[coh_idx][subject_idx][num_states] = t_store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the trained data so we dont have to train again and again\n",
    "# with open('all_subject_coh_train_report.pkl', 'wb') as f:\n",
    "#     pkl.dump(training_cache, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to radians\n",
    "# design_matrix[:,:,0] = np.deg2rad(design_matrix[:,:,0])\n",
    "# design_matrix[:,:,3] = np.deg2rad(design_matrix[:,:,3])\n",
    "\n",
    "# observation = np.deg2rad(observation)\n",
    "\n",
    "# Add flat biases column\n",
    "flat_biases = np.ones_like(design_matrix[:,:,:1])\n",
    "design_matrix =  np.concatenate([design_matrix, flat_biases], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle data\n",
    "shuff_idx = np.random.permutation(len(design_matrix))\n",
    "\n",
    "design_matrix = design_matrix[shuff_idx]\n",
    "observation = observation[shuff_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split it 80:20 for training and testing\n",
    "\n",
    "train_idx = int(0.8 * len(design_matrix))\n",
    "\n",
    "train_design = design_matrix[:train_idx]\n",
    "train_obs = observation[:train_idx]\n",
    "\n",
    "test_design = design_matrix[train_idx:]\n",
    "test_obs = observation[train_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to jax arrays\n",
    "train_emissions = jnp.array(train_obs)\n",
    "train_inputs = jnp.array(train_design)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A training cache to store all the models and their parameters\n",
    "training_cache = defaultdict(dict)\n",
    "\n",
    "# DS to store the models organized\n",
    "class Model_Store:\n",
    "    n_states: int\n",
    "    fit_model: None\n",
    "    fit_params: None\n",
    "    lps: None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_hmms(model_class, num_states, emission_dim, input_dim, train_emissions, train_inputs):\n",
    "    \n",
    "    model = model_class(num_states, input_dim, emission_dim)\n",
    "    parameters, properties = model.initialize(key=jr.PRNGKey(1))\n",
    "\n",
    "    # Fit with SGD\n",
    "    fit_params, lps = model.fit_sgd(params = parameters, \n",
    "                                    props = properties, \n",
    "                                    emissions = train_emissions, \n",
    "                                    inputs = train_inputs, \n",
    "                                    num_epochs = 5000, \n",
    "                                    optimizer = optax.adam(1e-4), \n",
    "                                    shuffle = False, \n",
    "                                    batch_size = 32)\n",
    "    \n",
    "    return model, fit_params, lps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(10):\n",
    "#     model, fit_params, lps = train_hmms(E_HMM, 2, 1, 5, train_emissions, train_inputs)\n",
    "#     print(f\"Model {i} trained - {lps[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: ET_HMM - 2 states\n",
      "[1.9862871 1.9824057 1.9785368 1.9746825 1.9708424 1.9670181 1.9632099\n",
      " 1.9594175 1.9556417 1.9518824]\n",
      "Training: ET_HMM - 3 states\n",
      "[1.9957613 1.9918696 1.98799   1.9841245 1.9802731 1.9764369 1.9726163\n",
      " 1.9688113 1.9650222 1.9612494]\n",
      "Training: ET_HMM - 4 states\n",
      "[1.9962769 1.9923809 1.9884971 1.9846271 1.9807719 1.9769317 1.973107\n",
      " 1.9692982 1.9655054 1.9617283]\n",
      "Training: ET_HMM - 5 states\n",
      "[1.9953004 1.9914081 1.9875284 1.9836622 1.9798106 1.9759741 1.9721533\n",
      " 1.9683479 1.964559  1.9607859]\n",
      "Training: ET_HMM - 6 states\n",
      "[1.9969393 1.9930414 1.989156  1.9852844 1.9814271 1.9775847 1.9737579\n",
      " 1.969947  1.9661516 1.9623725]\n",
      "Training: E_HMM - 2 states\n",
      "[1.9859469 1.9820644 1.9781945 1.9743389 1.970498  1.9666725 1.9628631\n",
      " 1.95907   1.955293  1.9515327]\n",
      "Training: E_HMM - 3 states\n",
      "[1.994876  1.9909754 1.9870872 1.9832131 1.9793533 1.9755088 1.9716797\n",
      " 1.9678665 1.9640694 1.9602884]\n",
      "Training: E_HMM - 4 states\n",
      "[1.9923513 1.9884495 1.9845606 1.9806852 1.9768249 1.9729798 1.9691504\n",
      " 1.9653372 1.96154   1.957759 ]\n",
      "Training: E_HMM - 5 states\n",
      "[1.9934614 1.9895662 1.9856837 1.9818151 1.977961  1.9741222 1.9702986\n",
      " 1.9664915 1.9627    1.9589249]\n",
      "Training: E_HMM - 6 states\n",
      "[1.9942696 1.9903662 1.9864758 1.9825987 1.9787368 1.9748892 1.9710577\n",
      " 1.9672421 1.9634424 1.9596586]\n",
      "Training: T_HMM - 2 states\n",
      "[1.9940063 1.9930128 1.9920224 1.9910356 1.9900526 1.9890732 1.9880981\n",
      " 1.987127  1.9861596 1.9851965]\n",
      "Training: T_HMM - 3 states\n",
      "[1.9990797 1.9980785 1.9970807 1.9960861 1.9950955 1.9941086 1.993126\n",
      " 1.9921472 1.9911726 1.9902017]\n",
      "Training: T_HMM - 4 states\n",
      "[1.9972824 1.9962834 1.9952877 1.9942955 1.9933071 1.9923226 1.9913422\n",
      " 1.9903654 1.9893931 1.9884243]\n",
      "Training: T_HMM - 5 states\n",
      "[1.9931532 1.99216   1.9911696 1.990183  1.9892    1.9882209 1.9872458\n",
      " 1.9862747 1.9853075 1.9843442]\n",
      "Training: T_HMM - 6 states\n",
      "[1.9956143 1.9946165 1.9936218 1.9926306 1.9916432 1.9906596 1.98968\n",
      " 1.9887043 1.9877328 1.9867651]\n"
     ]
    }
   ],
   "source": [
    "min_state, max_state = 2, 6\n",
    "emission_dim, input_dim = 1, 5\n",
    "\n",
    "for model_class in [ET_HMM, E_HMM, T_HMM]:\n",
    "\n",
    "    for num_states in range(min_state, max_state+1):\n",
    "        print(f'Training: {model_class.__name__} - {num_states} states')\n",
    "\n",
    "        model, fit_params, lps = train_hmms(model_class, num_states, emission_dim, input_dim, train_emissions, train_inputs)\n",
    "\n",
    "        print(f\"{lps[:10]}\")\n",
    "\n",
    "        t_store = Model_Store()\n",
    "        t_store.n_states = num_states\n",
    "        t_store.fit_model = model\n",
    "        t_store.fit_params = fit_params\n",
    "        t_store.lps = lps\n",
    "\n",
    "        training_cache[model_class.__name__][num_states] = t_store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParamsET_HMM(initial=ParamsStandardHMMInitialState(probs=Array([0.65643466, 0.34356534], dtype=float32)), transitions=ParamsET_Transitions(transition_matrix=Array([[0.93811536, 0.06188458],\n",
       "       [0.94132054, 0.05867945]], dtype=float32), transition_weights=Array([[-0.00764516, -0.00025098, -0.01133804, -0.00038295, -0.00130757],\n",
       "       [-0.00110481,  0.01022496, -0.00978904,  0.00814341,  0.00280931]],      dtype=float32)), emissions=ParamsET_Emissions(weights=Array([[[ 0.216029  ,  0.02790617,  0.01633381,  0.03509545,\n",
       "          1.3987256 ]],\n",
       "\n",
       "       [[ 0.06578622, -0.02190064,  0.04457312,  0.00982139,\n",
       "          0.39937398]]], dtype=float32), covs=Array([[[ 3.292194]],\n",
       "\n",
       "       [[11.952794]]], dtype=float32)))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_cache[\"ET_HMM\"][2].fit_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_cache[\"shuffle_idx\"] = shuff_idx\n",
    "\n",
    "# # Save the trained data so we dont have to train again and again\n",
    "# with open('training_cache.pkl', 'wb') as f:\n",
    "#     pkl.dump(training_cache, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
