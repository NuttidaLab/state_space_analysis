{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "from scipy.stats import circmean, circstd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from utils import validate_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set in stone\n",
    "data_path = '../axej/'\n",
    "n_subjects = 13\n",
    "n_sessions = 4\n",
    "n_runs = 6\n",
    "n_trials = 120\n",
    "n_ts = 500\n",
    "\n",
    "exp_ts = 1000\n",
    "\n",
    "# noise frames = 0 to 220 (250 - 30)\n",
    "noise_thresh = 0.5\n",
    "noise_gap = 30\n",
    "\n",
    "\n",
    "experiment_orientations = [159, 123, 87, 51, 15]\n",
    "subjects = [\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\" ,\"09\", \"10\", \"11\", \"12\", \"14\"]\n",
    "\n",
    "def get_calib(subj, sess):\n",
    "    mat_contents = loadmat(data_path + f'AxeJEEG_Subj{subjects[subj]}_S{sess+1}_Cali1.mat.mat', struct_as_record=False, squeeze_me=True)\n",
    "    return mat_contents[\"p\"].__dict__\n",
    "\n",
    "def get_run(subj, sess, run):\n",
    "    mat_contents = loadmat(data_path + f'AxeJEEG_Subj{subjects[subj]}_S{sess+1}_Run{run+1}.mat.mat', struct_as_record=False, squeeze_me=True)\n",
    "    return mat_contents[\"p\"].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:01<00:00,  6.87it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((13, 4, 6, 120, 500),\n",
       " (13, 4, 6, 120, 500),\n",
       " (13, 4, 6, 120),\n",
       " (13, 4, 6, 120),\n",
       " (13, 4, 6, 120),\n",
       " (13, 4, 6, 120),\n",
       " (13, 4, 6, 120))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all run data\n",
    "# subjexts x sessions x runs\n",
    "jx = []\n",
    "jy = []\n",
    "stimdir = []\n",
    "tgonset = []\n",
    "\n",
    "# Attention (attCue): tr_foc = 1, tr_div = 2\n",
    "# Coherence (tgCoh): tr_lo = 1, tr_hi = 2\n",
    "# ExpOrientation (expOri): 1,2,3,4,5 -> 159, 123, 87, 51, 15\n",
    "att = []\n",
    "coh = []\n",
    "exp = []\n",
    "\n",
    "for subj in tqdm(range(n_subjects)):\n",
    "    for sess in range(n_sessions):\n",
    "        for run in range(n_runs):\n",
    "\n",
    "            data = get_run(subj, sess, run)\n",
    "            jx.append(data[\"joyx\"])\n",
    "            jy.append(data[\"joyy\"])\n",
    "            stimdir.append(data[\"stimDirREAL\"])\n",
    "\n",
    "            f_tgonset = data[\"f_precuedur\"] + data[\"f_cuedur\"]\n",
    "            tgonset.append(f_tgonset)\n",
    "\n",
    "            att.append(data[\"attCue\"])\n",
    "            coh.append(data[\"tgCoh\"])\n",
    "\n",
    "            try:\n",
    "                # print(data[\"expOri\"])\n",
    "                exp.append([experiment_orientations[data[\"expOri\"] - 1]]*n_trials)\n",
    "            except:\n",
    "                # print(\"No expOri\")\n",
    "                exp.append([np.nan]*n_trials)\n",
    "                \n",
    "\n",
    "# Shape the run data\n",
    "jx = np.array(jx, dtype=np.float64).reshape(n_subjects, n_sessions, n_runs, n_trials, n_ts)\n",
    "jy = np.array(jy, dtype=np.float64).reshape(n_subjects, n_sessions, n_runs, n_trials, n_ts)\n",
    "stimdir = np.array(stimdir).reshape(n_subjects, n_sessions, n_runs, n_trials)\n",
    "tgonset = np.array(tgonset).reshape(n_subjects, n_sessions, n_runs, n_trials)\n",
    "att = np.array(att, dtype=np.float64).reshape(n_subjects, n_sessions, n_runs, n_trials)\n",
    "coh = np.array(coh, dtype=np.float64).reshape(n_subjects, n_sessions, n_runs, n_trials)\n",
    "exp = np.array(exp, dtype=np.float64).reshape(n_subjects, n_sessions, n_runs, n_trials)\n",
    "\n",
    "jx.shape, jy.shape, stimdir.shape, tgonset.shape, att.shape, coh.shape, exp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logic for Getting Valid Trials:\n",
    "\n",
    "1. Get all the trials\n",
    "2. Align all target onset at 250 ts\n",
    "3. Get distance from center and angle from center\n",
    "4. If the distance moves <0.4 au n frames before target onset. Then that trial is \"too early\" and all response set nan.\n",
    "5. If ts has distance > 1 au then set its response angle to the last valid angle (if first, the nan) and set that distance to 1.\n",
    "6. get angle first distance = 1 a.u. instance after target onset. or if it never reaches 1, then angle at max distance after target onset. as the response angle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "shifted_jx, shifted_jy, dist_from_cent, resp_angle, final_resp_angles = validate_data(n_subjects, n_sessions, n_runs, n_trials, n_ts, exp_ts, jx, jy, tgonset, noise_thresh, noise_gap, do_noise_thresh=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 removed trials\n",
      "0.0 % removed trials\n"
     ]
    }
   ],
   "source": [
    "# Get all trials where angles are only nan\n",
    "nan_trials = np.where(np.isnan(resp_angle).all(axis=-1))\n",
    "print(nan_trials[0].shape[0], \"removed trials\")\n",
    "print(nan_trials[0].shape[0] / (n_subjects * n_sessions * n_runs * n_trials) * 100, \"% removed trials\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Circular stat defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def circdist(a, b):\n",
    "    return min(abs(a-b), 360-abs(a-b))\n",
    "\n",
    "def circmedian(angs):\n",
    "    angs = np.array(angs)\n",
    "    angs = angs[~np.isnan(angs)]\n",
    "    pdists = angs[np.newaxis, :] - angs[:, np.newaxis]\n",
    "    pdists = (pdists + 180) % (2 * 180) - 180\n",
    "    pdists = np.abs(pdists).sum(1)\n",
    "    return angs[np.argmin(pdists)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "calib_median = np.load(\"../analysis/cache/circ_median.npy\")\n",
    "median_key = {15:0, 51:1, 87:2, 123:3, 159:4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "calib_std = np.load(\"../analysis/cache/circ_std.npy\")\n",
    "std_key = {15:0, 51:1, 87:2, 123:3, 159:4}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design Matrix\n",
    "\n",
    "Things that are considered as u_t\n",
    "\n",
    "- Calibrated stimulus (median)\n",
    "- Coherece\n",
    "- Attention \n",
    "- Expectation\n",
    "\n",
    "compared:\n",
    "\n",
    "- bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13, 4, 6, 120), (13, 4, 6, 120), (13, 4, 6, 120))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_resp_angles.shape, stimdir.shape, exp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stimulus = np.zeros((n_subjects, n_sessions, n_runs, n_trials))\n",
    "exp_cali = np.zeros((n_subjects, n_sessions, n_runs, n_trials))\n",
    "\n",
    "for subj in range(n_subjects):\n",
    "    for sess in range(n_sessions):\n",
    "        for run in range(n_runs):\n",
    "            for trial in range(n_trials):\n",
    "                target_key = median_key[stimdir[subj, sess, run, trial]]\n",
    "                stimulus[subj, sess, run, trial] = calib_median[subj, target_key]\n",
    "\n",
    "                exp_t = exp[subj, sess, run, trial]\n",
    "                if np.isnan(exp_t):\n",
    "                    exp_cali[subj, sess, run, trial] = np.nan\n",
    "                else:\n",
    "                    exp_key = median_key[exp_t]\n",
    "                    exp_cali[subj, sess, run, trial] = calib_median[subj, exp_key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attention + Coherence + Expectation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coherence (tgCoh): tr_lo = 1, tr_hi = 2\n",
    "# coh = []\n",
    "\n",
    "# Attention (attCue): tr_foc = 1, tr_div = 2\n",
    "# att = []\n",
    "\n",
    "# ExpOrientation (expOri): 1,2,3,4,5 -> 159, 123, 87, 51, 15 -> calib_median\n",
    "# exp_cali = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13, 4, 6, 120), (13, 4, 6, 120), (13, 4, 6, 120))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coh.shape, att.shape, exp_cali.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "coh[coh == 1] = 0\n",
    "coh[coh == 2] = 1\n",
    "\n",
    "att[att == 1] = 1\n",
    "att[att == 2] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup and standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13, 4, 5, 120),\n",
       " (13, 4, 5, 120),\n",
       " (13, 4, 5, 120),\n",
       " (13, 4, 5, 120),\n",
       " (260, 120),\n",
       " (260, 120, 4))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove trials with no expectation manipulation\n",
    "\n",
    "exp_obs = final_resp_angles[:, :, :5, :].reshape(-1, 120)\n",
    "\n",
    "exp_stim = stimulus[:, :, :5, :]\n",
    "exp_coh = coh[:, :, :5, :]\n",
    "exp_att = att[:, :, :5, :]\n",
    "exp_exp = exp_cali[:, :, :5, :]\n",
    "\n",
    "exp_design_matrix = np.stack([exp_stim, exp_coh, exp_att, exp_exp], axis=-1).reshape(-1, 120, 4)\n",
    "\n",
    "exp_stim.shape, exp_coh.shape, exp_att.shape, exp_exp.shape, exp_obs.shape, exp_design_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((260, 120, 1), (260, 120, 4))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_obs = np.expand_dims(np.array(exp_obs), -1)\n",
    "valid_design = np.array(exp_design_matrix)\n",
    "\n",
    "valid_obs.shape, valid_design.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(\"../analysis/cache/exp_obs.npy\", valid_obs)\n",
    "# np.save(\"../analysis/cache/exp_design.npy\", valid_design)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
