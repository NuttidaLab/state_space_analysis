{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/tmp/ipykernel_429514/3824077815.py\", line 66, in run_mcmc  *\n        trace_fn=lambda current_state, kernel_results: kernel_results\n    File \"/home/nuttidalab/miniconda3/envs/ssm/lib/python3.10/site-packages/tensorflow_probability/python/mcmc/sample.py\", line 330, in sample_chain  **\n        previous_kernel_results = kernel.bootstrap_results(current_state)\n    File \"/home/nuttidalab/miniconda3/envs/ssm/lib/python3.10/site-packages/tensorflow_probability/python/mcmc/simple_step_size_adaptation.py\", line 443, in bootstrap_results\n        inner_results = self.inner_kernel.bootstrap_results(init_state)\n    File \"/home/nuttidalab/miniconda3/envs/ssm/lib/python3.10/site-packages/tensorflow_probability/python/mcmc/nuts.py\", line 468, in bootstrap_results\n        ] = leapfrog_impl.process_args(self.target_log_prob_fn, dummy_momentum,\n    File \"/home/nuttidalab/miniconda3/envs/ssm/lib/python3.10/site-packages/tensorflow_probability/python/mcmc/internal/leapfrog_integrator.py\", line 378, in process_args\n        [target, target_grad_parts] = mcmc_util.maybe_call_fn_and_grads(\n    File \"/home/nuttidalab/miniconda3/envs/ssm/lib/python3.10/site-packages/tensorflow_probability/python/mcmc/internal/util.py\", line 297, in maybe_call_fn_and_grads\n        result, grads = _value_and_gradients(fn, fn_arg_list, result, grads)\n    File \"/home/nuttidalab/miniconda3/envs/ssm/lib/python3.10/site-packages/tensorflow_probability/python/mcmc/internal/util.py\", line 265, in _value_and_gradients\n        return tfp_math_value_and_gradients(fn, fn_arg_list)\n    File \"/home/nuttidalab/miniconda3/envs/ssm/lib/python3.10/site-packages/tensorflow_probability/python/math/gradient.py\", line 108, in value_and_gradient\n        return _value_and_grad_impl(\n    File \"/home/nuttidalab/miniconda3/envs/ssm/lib/python3.10/site-packages/tensorflow_probability/python/math/gradient.py\", line 378, in _value_and_grad_impl\n        y, dydx, aux = grad_fn(lambda: f(*args, **kwargs) if _has_args(f) else f(),\n    File \"/home/nuttidalab/miniconda3/envs/ssm/lib/python3.10/site-packages/tensorflow_probability/python/math/gradient.py\", line 330, in _gradient_old\n        y, aux = f()\n    File \"/home/nuttidalab/miniconda3/envs/ssm/lib/python3.10/site-packages/tensorflow_probability/python/math/gradient.py\", line 378, in <lambda>\n        y, dydx, aux = grad_fn(lambda: f(*args, **kwargs) if _has_args(f) else f(),\n    File \"/home/nuttidalab/miniconda3/envs/ssm/lib/python3.10/site-packages/tensorflow_probability/python/math/gradient.py\", line 375, in <lambda>\n        f = lambda *args, **kwargs: (real_f(*args, **kwargs)  # pylint: disable=g-long-lambda\n    File \"/tmp/ipykernel_429514/3824077815.py\", line 43, in target_log_prob_fn\n        return joint_distribution.log_prob((a, b, w, kappa, y))\n    File \"/home/nuttidalab/miniconda3/envs/ssm/lib/python3.10/site-packages/tensorflow_probability/python/distributions/joint_distribution.py\", line 899, in log_prob\n        return self._call_log_prob(self._resolve_value(*args, **kwargs), name=name)\n    File \"/home/nuttidalab/miniconda3/envs/ssm/lib/python3.10/site-packages/tensorflow_probability/python/distributions/distribution.py\", line 1269, in _call_log_prob\n        return self._log_prob(value, **kwargs)\n    File \"/home/nuttidalab/miniconda3/envs/ssm/lib/python3.10/site-packages/tensorflow_probability/python/distributions/joint_distribution.py\", line 677, in _log_prob\n        self._map_measure_over_dists('log_prob', value))\n    File \"/home/nuttidalab/miniconda3/envs/ssm/lib/python3.10/site-packages/tensorflow_probability/python/distributions/joint_distribution.py\", line 742, in _map_measure_over_dists\n        return self._call_execute_model(\n    File \"/home/nuttidalab/miniconda3/envs/ssm/lib/python3.10/site-packages/tensorflow_probability/python/distributions/joint_distribution.py\", line 850, in _call_execute_model\n        return self._execute_model(\n    File \"/home/nuttidalab/miniconda3/envs/ssm/lib/python3.10/site-packages/tensorflow_probability/python/distributions/joint_distribution.py\", line 1047, in _execute_model\n        d = gen.send(next_value)\n    File \"/tmp/ipykernel_429514/3824077815.py\", line 26, in model\n        mu = tf.linalg.matmul(u, tf.transpose(w))       # Shape: [T, K]  # Changed here\n\n    ValueError: Shape must be rank 2 but is rank 1 for '{{node mcmc_sample_chain/simple_step_size_adaptation___init__/_bootstrap_results/NoUTurnSampler/.bootstrap_results/process_args/maybe_call_fn_and_grads/value_and_gradients/value_and_gradient/JointDistributionCoroutineAutoBatched_CONSTRUCTED_AT_top_level/log_prob/MatMul_1}} = MatMul[T=DT_FLOAT, grad_a=false, grad_b=false, transpose_a=false, transpose_b=false](mcmc_sample_chain/simple_step_size_adaptation___init__/_bootstrap_results/NoUTurnSampler/.bootstrap_results/process_args/maybe_call_fn_and_grads/value_and_gradients/value_and_gradient/MatMul/a, mcmc_sample_chain/simple_step_size_adaptation___init__/_bootstrap_results/NoUTurnSampler/.bootstrap_results/process_args/maybe_call_fn_and_grads/value_and_gradients/value_and_gradient/JointDistributionCoroutineAutoBatched_CONSTRUCTED_AT_top_level/log_prob/transpose_1)' with input shapes: [100,2], [2].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 70\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tfp\u001b[38;5;241m.\u001b[39mmcmc\u001b[38;5;241m.\u001b[39msample_chain(\n\u001b[1;32m     62\u001b[0m         num_results\u001b[38;5;241m=\u001b[39mnum_results,\n\u001b[1;32m     63\u001b[0m         current_state\u001b[38;5;241m=\u001b[39m[tf\u001b[38;5;241m.\u001b[39mzeros(K), tf\u001b[38;5;241m.\u001b[39mzeros([K, P]), tf\u001b[38;5;241m.\u001b[39mzeros(P), tf\u001b[38;5;241m.\u001b[39mones(K)],  \u001b[38;5;66;03m# Initial states for [a, b, w, kappa]\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m         trace_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m current_state, kernel_results: kernel_results\n\u001b[1;32m     67\u001b[0m     )\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Perform MCMC sampling\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m samples, kernel_results \u001b[38;5;241m=\u001b[39m \u001b[43mrun_mcmc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# Posterior samples for each parameter\u001b[39;00m\n\u001b[1;32m     73\u001b[0m a_samples, b_samples, w_samples, kappa_samples \u001b[38;5;241m=\u001b[39m samples\n",
      "File \u001b[0;32m~/miniconda3/envs/ssm/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filejx3ca2y2.py:12\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__run_mcmc\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     11\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tfp)\u001b[38;5;241m.\u001b[39mmcmc\u001b[38;5;241m.\u001b[39msample_chain, (), \u001b[38;5;28mdict\u001b[39m(num_results\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(num_results), current_state\u001b[38;5;241m=\u001b[39m[ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mzeros, (ag__\u001b[38;5;241m.\u001b[39mld(K),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope), ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mzeros, ([ag__\u001b[38;5;241m.\u001b[39mld(K), ag__\u001b[38;5;241m.\u001b[39mld(P)],), \u001b[38;5;28;01mNone\u001b[39;00m, fscope), ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mzeros, (ag__\u001b[38;5;241m.\u001b[39mld(P),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope), ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mones, (ag__\u001b[38;5;241m.\u001b[39mld(K),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)], kernel\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(kernel), num_burnin_steps\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(num_burnin_steps), trace_fn\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mautograph_artifact(\u001b[38;5;28;01mlambda\u001b[39;00m current_state, kernel_results: ag__\u001b[38;5;241m.\u001b[39mld(kernel_results))), fscope)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ssm/lib/python3.10/site-packages/tensorflow_probability/python/mcmc/sample.py:330\u001b[0m, in \u001b[0;36msample_chain\u001b[0;34m(num_results, current_state, previous_kernel_results, kernel, num_burnin_steps, num_steps_between_results, trace_fn, return_final_kernel_results, parallel_iterations, seed, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m current_state \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m x: tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(x, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcurrent_state\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m    328\u001b[0m     current_state)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m previous_kernel_results \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 330\u001b[0m   previous_kernel_results \u001b[38;5;241m=\u001b[39m \u001b[43mkernel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    333\u001b[0m   \u001b[38;5;66;03m# It simplifies the logic to use a dummy function here.\u001b[39;00m\n\u001b[1;32m    334\u001b[0m   trace_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs: ()\n",
      "File \u001b[0;32m~/miniconda3/envs/ssm/lib/python3.10/site-packages/tensorflow_probability/python/mcmc/simple_step_size_adaptation.py:443\u001b[0m, in \u001b[0;36mSimpleStepSizeAdaptation.bootstrap_results\u001b[0;34m(self, init_state)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbootstrap_results\u001b[39m(\u001b[38;5;28mself\u001b[39m, init_state):\n\u001b[1;32m    441\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mname_scope(mcmc_util\u001b[38;5;241m.\u001b[39mmake_name(\n\u001b[1;32m    442\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msimple_step_size_adaptation\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbootstrap_results\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[0;32m--> 443\u001b[0m     inner_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minner_kernel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    444\u001b[0m     step_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_size_getter_fn(inner_results)\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SimpleStepSizeAdaptationResults(\n\u001b[1;32m    446\u001b[0m         inner_results\u001b[38;5;241m=\u001b[39minner_results,\n\u001b[1;32m    447\u001b[0m         step\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mconstant(\u001b[38;5;241m0\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mint32),\n\u001b[1;32m    448\u001b[0m         target_accept_prob\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget_accept_prob\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    449\u001b[0m         adaptation_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madaptation_rate\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    450\u001b[0m         new_step_size\u001b[38;5;241m=\u001b[39mstep_size)\n",
      "File \u001b[0;32m~/miniconda3/envs/ssm/lib/python3.10/site-packages/tensorflow_probability/python/mcmc/nuts.py:468\u001b[0m, in \u001b[0;36mNoUTurnSampler.bootstrap_results\u001b[0;34m(self, init_state)\u001b[0m\n\u001b[1;32m    460\u001b[0m   init_state \u001b[38;5;241m=\u001b[39m [init_state]\n\u001b[1;32m    461\u001b[0m dummy_momentum \u001b[38;5;241m=\u001b[39m [tf\u001b[38;5;241m.\u001b[39mones_like(state) \u001b[38;5;28;01mfor\u001b[39;00m state \u001b[38;5;129;01min\u001b[39;00m init_state]\n\u001b[1;32m    463\u001b[0m [\n\u001b[1;32m    464\u001b[0m     _,\n\u001b[1;32m    465\u001b[0m     _,\n\u001b[1;32m    466\u001b[0m     current_target_log_prob,\n\u001b[1;32m    467\u001b[0m     current_grads_log_prob,\n\u001b[0;32m--> 468\u001b[0m ] \u001b[38;5;241m=\u001b[39m \u001b[43mleapfrog_impl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_log_prob_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdummy_momentum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m                               \u001b[49m\u001b[43minit_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;66;03m# Confirm that the step size is compatible with the state parts.\u001b[39;00m\n\u001b[1;32m    472\u001b[0m _ \u001b[38;5;241m=\u001b[39m _prepare_step_size(\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_size, current_target_log_prob\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;28mlen\u001b[39m(init_state))\n",
      "File \u001b[0;32m~/miniconda3/envs/ssm/lib/python3.10/site-packages/tensorflow_probability/python/mcmc/internal/leapfrog_integrator.py:378\u001b[0m, in \u001b[0;36mprocess_args\u001b[0;34m(target_fn, momentum_parts, state_parts, target, target_grad_parts)\u001b[0m\n\u001b[1;32m    373\u001b[0m state_parts \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    374\u001b[0m     tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(\n\u001b[1;32m    375\u001b[0m         v, dtype_hint\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mfloat32, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate_parts\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m state_parts]\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m target_grad_parts \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 378\u001b[0m   [target, target_grad_parts] \u001b[38;5;241m=\u001b[39m \u001b[43mmcmc_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaybe_call_fn_and_grads\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtarget_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_parts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    381\u001b[0m   target \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(\n\u001b[1;32m    382\u001b[0m       target, dtype_hint\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mfloat32, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/ssm/lib/python3.10/site-packages/tensorflow_probability/python/mcmc/internal/util.py:297\u001b[0m, in \u001b[0;36mmaybe_call_fn_and_grads\u001b[0;34m(fn, fn_arg_list, result, grads, check_non_none_grads, name)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mname_scope(name \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaybe_call_fn_and_grads\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    295\u001b[0m   fn_arg_list \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlist\u001b[39m(fn_arg_list) \u001b[38;5;28;01mif\u001b[39;00m is_list_like(fn_arg_list)\n\u001b[1;32m    296\u001b[0m                  \u001b[38;5;28;01melse\u001b[39;00m [fn_arg_list])\n\u001b[0;32m--> 297\u001b[0m   result, grads \u001b[38;5;241m=\u001b[39m \u001b[43m_value_and_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn_arg_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    298\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(dtype_util\u001b[38;5;241m.\u001b[39mis_floating(r\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    299\u001b[0m              \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m (result \u001b[38;5;28;01mif\u001b[39;00m is_list_like(result) \u001b[38;5;28;01melse\u001b[39;00m [result])):  \u001b[38;5;66;03m# pylint: disable=superfluous-parens\u001b[39;00m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFunction result must be a `Tensor` with `float` \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    301\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`dtype`.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/ssm/lib/python3.10/site-packages/tensorflow_probability/python/mcmc/internal/util.py:265\u001b[0m, in \u001b[0;36m_value_and_gradients\u001b[0;34m(fn, fn_arg_list, result, grads, name)\u001b[0m\n\u001b[1;32m    258\u001b[0m fn_arg_list \u001b[38;5;241m=\u001b[39m _convert_to_tensor(fn_arg_list, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfn_arg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m grads \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m (JAX_MODE \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m    261\u001b[0m                                          \u001b[38;5;129;01mnot\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mexecuting_eagerly()):\n\u001b[1;32m    262\u001b[0m   \u001b[38;5;66;03m# Currently, computing gradient is not working well with caching in\u001b[39;00m\n\u001b[1;32m    263\u001b[0m   \u001b[38;5;66;03m# tensorflow eager mode (see below), so we will handle that case\u001b[39;00m\n\u001b[1;32m    264\u001b[0m   \u001b[38;5;66;03m# separately.\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtfp_math_value_and_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn_arg_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    268\u001b[0m   result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39mfn_arg_list)\n",
      "File \u001b[0;32m~/miniconda3/envs/ssm/lib/python3.10/site-packages/tensorflow_probability/python/math/gradient.py:108\u001b[0m, in \u001b[0;36mvalue_and_gradient\u001b[0;34m(f, output_gradients, use_gradient_tape, auto_unpack_single_arg, has_aux, name, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Computes `f(*args, **kwargs)` and its gradients wrt to `args`, `kwargs`.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \n\u001b[1;32m     38\u001b[0m \u001b[38;5;124;03mThe function `f` is invoked according to one of the following rules:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;124;03m    are the gradients of `y` with respect to each of `args` and `kwargs`.\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mname_scope(name \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue_and_gradient\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 108\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_value_and_grad_impl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m      \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_gradient_new\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecuting_eagerly\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43muse_gradient_tape\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\n\u001b[1;32m    111\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_gradient_old\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m      \u001b[49m\u001b[43mauto_unpack_single_arg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauto_unpack_single_arg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m      \u001b[49m\u001b[43mexpand_tf_modules_as_trainable_vars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m      \u001b[49m\u001b[43mhas_aux\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_aux\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ssm/lib/python3.10/site-packages/tensorflow_probability/python/math/gradient.py:378\u001b[0m, in \u001b[0;36m_value_and_grad_impl\u001b[0;34m(f, grad_fn, output_gradients, auto_unpack_single_arg, expand_tf_modules_as_trainable_vars, has_aux, *args, **kwargs)\u001b[0m\n\u001b[1;32m    374\u001b[0m   real_f \u001b[38;5;241m=\u001b[39m f\n\u001b[1;32m    375\u001b[0m   f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: (real_f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# pylint: disable=g-long-lambda\u001b[39;00m\n\u001b[1;32m    376\u001b[0m                                \u001b[38;5;28;01mif\u001b[39;00m _has_args(real_f) \u001b[38;5;28;01melse\u001b[39;00m real_f(), ())\n\u001b[0;32m--> 378\u001b[0m y, dydx, aux \u001b[38;5;241m=\u001b[39m \u001b[43mgrad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_has_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mexpand_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpand_kwargs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m                       \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    381\u001b[0m dydx_args, dydx_kwargs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mpack_sequence_as(\n\u001b[1;32m    382\u001b[0m     [expand_args, expand_kwargs], dydx)\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m do_unpack:\n",
      "File \u001b[0;32m~/miniconda3/envs/ssm/lib/python3.10/site-packages/tensorflow_probability/python/math/gradient.py:330\u001b[0m, in \u001b[0;36m_gradient_old\u001b[0;34m(f, xs, grad_ys)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_gradient_old\u001b[39m(f, xs, grad_ys):\n\u001b[1;32m    329\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mexecuting_eagerly()\n\u001b[0;32m--> 330\u001b[0m   y, aux \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    331\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m y, tf\u001b[38;5;241m.\u001b[39mgradients(y, xs, grad_ys\u001b[38;5;241m=\u001b[39mgrad_ys), aux\n",
      "File \u001b[0;32m~/miniconda3/envs/ssm/lib/python3.10/site-packages/tensorflow_probability/python/math/gradient.py:378\u001b[0m, in \u001b[0;36m_value_and_grad_impl.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    374\u001b[0m   real_f \u001b[38;5;241m=\u001b[39m f\n\u001b[1;32m    375\u001b[0m   f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: (real_f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# pylint: disable=g-long-lambda\u001b[39;00m\n\u001b[1;32m    376\u001b[0m                                \u001b[38;5;28;01mif\u001b[39;00m _has_args(real_f) \u001b[38;5;28;01melse\u001b[39;00m real_f(), ())\n\u001b[0;32m--> 378\u001b[0m y, dydx, aux \u001b[38;5;241m=\u001b[39m grad_fn(\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m _has_args(f) \u001b[38;5;28;01melse\u001b[39;00m f(),\n\u001b[1;32m    379\u001b[0m                        tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten([expand_args, expand_kwargs]),\n\u001b[1;32m    380\u001b[0m                        output_gradients)\n\u001b[1;32m    381\u001b[0m dydx_args, dydx_kwargs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mpack_sequence_as(\n\u001b[1;32m    382\u001b[0m     [expand_args, expand_kwargs], dydx)\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m do_unpack:\n",
      "File \u001b[0;32m~/miniconda3/envs/ssm/lib/python3.10/site-packages/tensorflow_probability/python/math/gradient.py:375\u001b[0m, in \u001b[0;36m_value_and_grad_impl.<locals>.<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_aux:\n\u001b[1;32m    374\u001b[0m   real_f \u001b[38;5;241m=\u001b[39m f\n\u001b[0;32m--> 375\u001b[0m   f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: (\u001b[43mreal_f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=g-long-lambda\u001b[39;00m\n\u001b[1;32m    376\u001b[0m                                \u001b[38;5;28;01mif\u001b[39;00m _has_args(real_f) \u001b[38;5;28;01melse\u001b[39;00m real_f(), ())\n\u001b[1;32m    378\u001b[0m y, dydx, aux \u001b[38;5;241m=\u001b[39m grad_fn(\u001b[38;5;28;01mlambda\u001b[39;00m: f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mif\u001b[39;00m _has_args(f) \u001b[38;5;28;01melse\u001b[39;00m f(),\n\u001b[1;32m    379\u001b[0m                        tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten([expand_args, expand_kwargs]),\n\u001b[1;32m    380\u001b[0m                        output_gradients)\n\u001b[1;32m    381\u001b[0m dydx_args, dydx_kwargs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mpack_sequence_as(\n\u001b[1;32m    382\u001b[0m     [expand_args, expand_kwargs], dydx)\n",
      "Cell \u001b[0;32mIn[3], line 43\u001b[0m, in \u001b[0;36mtarget_log_prob_fn\u001b[0;34m(a, b, w, kappa)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtarget_log_prob_fn\u001b[39m(a, b, w, kappa):\n\u001b[0;32m---> 43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjoint_distribution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkappa\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ssm/lib/python3.10/site-packages/tensorflow_probability/python/distributions/joint_distribution.py:899\u001b[0m, in \u001b[0;36mJointDistribution.log_prob\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Log probability density/mass function.\u001b[39;00m\n\u001b[1;32m    891\u001b[0m \n\u001b[1;32m    892\u001b[0m \u001b[38;5;124;03m${calling_convention_description}\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    896\u001b[0m \u001b[38;5;124;03m    values of type `self.dtype`.\u001b[39;00m\n\u001b[1;32m    897\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    898\u001b[0m name \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog_prob\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 899\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_log_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resolve_value\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ssm/lib/python3.10/site-packages/tensorflow_probability/python/distributions/distribution.py:1269\u001b[0m, in \u001b[0;36mDistribution._call_log_prob\u001b[0;34m(self, value, name, **kwargs)\u001b[0m\n\u001b[1;32m   1267\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name_and_control_scope(name, value, kwargs):\n\u001b[1;32m   1268\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_log_prob\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m-> 1269\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1270\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_prob\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m   1271\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prob(value, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n",
      "File \u001b[0;32m~/miniconda3/envs/ssm/lib/python3.10/site-packages/tensorflow_probability/python/distributions/joint_distribution.py:677\u001b[0m, in \u001b[0;36mJointDistribution._log_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_log_prob\u001b[39m(\u001b[38;5;28mself\u001b[39m, value):\n\u001b[1;32m    676\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reduce_log_probs_over_dists(\n\u001b[0;32m--> 677\u001b[0m       \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_measure_over_dists\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlog_prob\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/ssm/lib/python3.10/site-packages/tensorflow_probability/python/distributions/joint_distribution.py:742\u001b[0m, in \u001b[0;36mJointDistribution._map_measure_over_dists\u001b[0;34m(self, attr, value)\u001b[0m\n\u001b[1;32m    739\u001b[0m   attr_name \u001b[38;5;241m=\u001b[39m attr\n\u001b[1;32m    740\u001b[0m   attr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m d, x: \u001b[38;5;28mgetattr\u001b[39m(d, attr_name)(x)\n\u001b[0;32m--> 742\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_execute_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    743\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    744\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    745\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msamplers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_and_trace_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mValueWithTrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=g-long-lambda\u001b[39;49;00m\n\u001b[1;32m    748\u001b[0m \u001b[43m                                                \u001b[49m\u001b[43mtraced\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ssm/lib/python3.10/site-packages/tensorflow_probability/python/distributions/joint_distribution.py:850\u001b[0m, in \u001b[0;36mJointDistribution._call_execute_model\u001b[0;34m(self, sample_shape, seed, value, sample_and_trace_fn)\u001b[0m\n\u001b[1;32m    846\u001b[0m   use_vectorized_map \u001b[38;5;241m=\u001b[39m (sample_shape_may_be_nontrivial \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m    847\u001b[0m                         value_might_have_sample_dims)\n\u001b[1;32m    849\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_vectorized_map:\n\u001b[0;32m--> 850\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m      \u001b[49m\u001b[43msample_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflat_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m      \u001b[49m\u001b[43msample_and_trace_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_and_trace_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;66;03m# Set up for autovectorized sampling. To support the `value` arg, we need to\u001b[39;00m\n\u001b[1;32m    855\u001b[0m \u001b[38;5;66;03m# first understand which dims are from the model itself, then wrap\u001b[39;00m\n\u001b[1;32m    856\u001b[0m \u001b[38;5;66;03m# `_call_execute_model` to batch over all remaining dims.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m flat_value_core_ndims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ssm/lib/python3.10/site-packages/tensorflow_probability/python/distributions/joint_distribution.py:1047\u001b[0m, in \u001b[0;36mJointDistribution._execute_model\u001b[0;34m(self, sample_shape, seed, value, stop_index, sample_and_trace_fn)\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stop_index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m index \u001b[38;5;241m==\u001b[39m stop_index:\n\u001b[1;32m   1046\u001b[0m       \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 1047\u001b[0m     d \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(next_value)\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m   1049\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 26\u001b[0m, in \u001b[0;36mmodel\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m class_probs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39msoftmax(eta)                \u001b[38;5;66;03m# Shape: [T, K]\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Mean direction for each component\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m mu \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m       \u001b[38;5;66;03m# Shape: [T, K]  # Changed here\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Expand kappa dimensions if necessary\u001b[39;00m\n\u001b[1;32m     29\u001b[0m kappa_expanded \u001b[38;5;241m=\u001b[39m kappa[tf\u001b[38;5;241m.\u001b[39mnewaxis, :]           \u001b[38;5;66;03m# Shape: [1, K]\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/tmp/ipykernel_429514/3824077815.py\", line 66, in run_mcmc  *\n        trace_fn=lambda current_state, kernel_results: kernel_results\n    File \"/home/nuttidalab/miniconda3/envs/ssm/lib/python3.10/site-packages/tensorflow_probability/python/mcmc/sample.py\", line 330, in sample_chain  **\n        previous_kernel_results = kernel.bootstrap_results(current_state)\n    File \"/home/nuttidalab/miniconda3/envs/ssm/lib/python3.10/site-packages/tensorflow_probability/python/mcmc/simple_step_size_adaptation.py\", line 443, in bootstrap_results\n        inner_results = self.inner_kernel.bootstrap_results(init_state)\n    File \"/home/nuttidalab/miniconda3/envs/ssm/lib/python3.10/site-packages/tensorflow_probability/python/mcmc/nuts.py\", line 468, in bootstrap_results\n        ] = leapfrog_impl.process_args(self.target_log_prob_fn, dummy_momentum,\n    File \"/home/nuttidalab/miniconda3/envs/ssm/lib/python3.10/site-packages/tensorflow_probability/python/mcmc/internal/leapfrog_integrator.py\", line 378, in process_args\n        [target, target_grad_parts] = mcmc_util.maybe_call_fn_and_grads(\n    File \"/home/nuttidalab/miniconda3/envs/ssm/lib/python3.10/site-packages/tensorflow_probability/python/mcmc/internal/util.py\", line 297, in maybe_call_fn_and_grads\n        result, grads = _value_and_gradients(fn, fn_arg_list, result, grads)\n    File \"/home/nuttidalab/miniconda3/envs/ssm/lib/python3.10/site-packages/tensorflow_probability/python/mcmc/internal/util.py\", line 265, in _value_and_gradients\n        return tfp_math_value_and_gradients(fn, fn_arg_list)\n    File \"/home/nuttidalab/miniconda3/envs/ssm/lib/python3.10/site-packages/tensorflow_probability/python/math/gradient.py\", line 108, in value_and_gradient\n        return _value_and_grad_impl(\n    File \"/home/nuttidalab/miniconda3/envs/ssm/lib/python3.10/site-packages/tensorflow_probability/python/math/gradient.py\", line 378, in _value_and_grad_impl\n        y, dydx, aux = grad_fn(lambda: f(*args, **kwargs) if _has_args(f) else f(),\n    File \"/home/nuttidalab/miniconda3/envs/ssm/lib/python3.10/site-packages/tensorflow_probability/python/math/gradient.py\", line 330, in _gradient_old\n        y, aux = f()\n    File \"/home/nuttidalab/miniconda3/envs/ssm/lib/python3.10/site-packages/tensorflow_probability/python/math/gradient.py\", line 378, in <lambda>\n        y, dydx, aux = grad_fn(lambda: f(*args, **kwargs) if _has_args(f) else f(),\n    File \"/home/nuttidalab/miniconda3/envs/ssm/lib/python3.10/site-packages/tensorflow_probability/python/math/gradient.py\", line 375, in <lambda>\n        f = lambda *args, **kwargs: (real_f(*args, **kwargs)  # pylint: disable=g-long-lambda\n    File \"/tmp/ipykernel_429514/3824077815.py\", line 43, in target_log_prob_fn\n        return joint_distribution.log_prob((a, b, w, kappa, y))\n    File \"/home/nuttidalab/miniconda3/envs/ssm/lib/python3.10/site-packages/tensorflow_probability/python/distributions/joint_distribution.py\", line 899, in log_prob\n        return self._call_log_prob(self._resolve_value(*args, **kwargs), name=name)\n    File \"/home/nuttidalab/miniconda3/envs/ssm/lib/python3.10/site-packages/tensorflow_probability/python/distributions/distribution.py\", line 1269, in _call_log_prob\n        return self._log_prob(value, **kwargs)\n    File \"/home/nuttidalab/miniconda3/envs/ssm/lib/python3.10/site-packages/tensorflow_probability/python/distributions/joint_distribution.py\", line 677, in _log_prob\n        self._map_measure_over_dists('log_prob', value))\n    File \"/home/nuttidalab/miniconda3/envs/ssm/lib/python3.10/site-packages/tensorflow_probability/python/distributions/joint_distribution.py\", line 742, in _map_measure_over_dists\n        return self._call_execute_model(\n    File \"/home/nuttidalab/miniconda3/envs/ssm/lib/python3.10/site-packages/tensorflow_probability/python/distributions/joint_distribution.py\", line 850, in _call_execute_model\n        return self._execute_model(\n    File \"/home/nuttidalab/miniconda3/envs/ssm/lib/python3.10/site-packages/tensorflow_probability/python/distributions/joint_distribution.py\", line 1047, in _execute_model\n        d = gen.send(next_value)\n    File \"/tmp/ipykernel_429514/3824077815.py\", line 26, in model\n        mu = tf.linalg.matmul(u, tf.transpose(w))       # Shape: [T, K]  # Changed here\n\n    ValueError: Shape must be rank 2 but is rank 1 for '{{node mcmc_sample_chain/simple_step_size_adaptation___init__/_bootstrap_results/NoUTurnSampler/.bootstrap_results/process_args/maybe_call_fn_and_grads/value_and_gradients/value_and_gradient/JointDistributionCoroutineAutoBatched_CONSTRUCTED_AT_top_level/log_prob/MatMul_1}} = MatMul[T=DT_FLOAT, grad_a=false, grad_b=false, transpose_a=false, transpose_b=false](mcmc_sample_chain/simple_step_size_adaptation___init__/_bootstrap_results/NoUTurnSampler/.bootstrap_results/process_args/maybe_call_fn_and_grads/value_and_gradients/value_and_gradient/MatMul/a, mcmc_sample_chain/simple_step_size_adaptation___init__/_bootstrap_results/NoUTurnSampler/.bootstrap_results/process_args/maybe_call_fn_and_grads/value_and_gradients/value_and_gradient/JointDistributionCoroutineAutoBatched_CONSTRUCTED_AT_top_level/log_prob/transpose_1)' with input shapes: [100,2], [2].\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "\n",
    "# Dummy data placeholders\n",
    "T, K, P = 100, 3, 2  # Example values for number of observations, classes, and input variables\n",
    "u = tf.random.normal([T, P])            # Input variables\n",
    "y = tf.random.uniform([T], minval=-np.pi, maxval=np.pi)  # Observed outputs (angles in radians)\n",
    "\n",
    "# Model definition\n",
    "def model():\n",
    "    # Priors\n",
    "    a = yield tfd.Sample(tfd.Normal(0, 5), sample_shape=K, name=\"a\")\n",
    "    b = yield tfd.Sample(tfd.Normal(0, 5), sample_shape=[K, P], name=\"b\")\n",
    "    w = yield tfd.Sample(tfd.Normal(0, 5), sample_shape=[K, P], name=\"w\")  # Changed here\n",
    "    kappa = yield tfd.Sample(tfd.Gamma(2.0, 0.1), sample_shape=K, name=\"kappa\")\n",
    "    \n",
    "    # Compute eta and class probabilities\n",
    "    eta = tf.linalg.matmul(u, tf.transpose(b)) + a  # Shape: [T, K]\n",
    "    class_probs = tf.nn.softmax(eta)                # Shape: [T, K]\n",
    "    \n",
    "    # Mean direction for each component\n",
    "    mu = tf.linalg.matmul(u, tf.transpose(w))       # Shape: [T, K]  # Changed here\n",
    "    \n",
    "    # Expand kappa dimensions if necessary\n",
    "    kappa_expanded = kappa[tf.newaxis, :]           # Shape: [1, K]\n",
    "    \n",
    "    # Likelihood for mixture of von Mises distributions\n",
    "    y_obs = yield tfd.MixtureSameFamily(\n",
    "        mixture_distribution=tfd.Categorical(probs=class_probs),\n",
    "        components_distribution=tfd.VonMises(loc=mu, concentration=kappa_expanded),\n",
    "        name=\"y_obs\"\n",
    "    )\n",
    "\n",
    "# Create the model's joint distribution\n",
    "joint_distribution = tfd.JointDistributionCoroutineAutoBatched(model)\n",
    "\n",
    "# Define the target log probability function for MCMC\n",
    "def target_log_prob_fn(a, b, w, kappa):\n",
    "    return joint_distribution.log_prob((a, b, w, kappa, y))\n",
    "\n",
    "# Initialize the HMC transition kernel (or NUTS for automatic tuning)\n",
    "num_burnin_steps = 500\n",
    "num_results = 1000\n",
    "kernel = tfp.mcmc.NoUTurnSampler(\n",
    "    target_log_prob_fn=target_log_prob_fn,\n",
    "    step_size=0.1\n",
    ")\n",
    "\n",
    "# Wrap kernel with a SimpleStepSizeAdaptation for tuning\n",
    "kernel = tfp.mcmc.SimpleStepSizeAdaptation(\n",
    "    kernel, num_adaptation_steps=int(0.8 * num_burnin_steps)\n",
    ")\n",
    "\n",
    "# Run MCMC to sample from the posterior\n",
    "@tf.function\n",
    "def run_mcmc():\n",
    "    return tfp.mcmc.sample_chain(\n",
    "        num_results=num_results,\n",
    "        current_state=[tf.zeros(K), tf.zeros([K, P]), tf.zeros(P), tf.ones(K)],  # Initial states for [a, b, w, kappa]\n",
    "        kernel=kernel,\n",
    "        num_burnin_steps=num_burnin_steps,\n",
    "        trace_fn=lambda current_state, kernel_results: kernel_results\n",
    "    )\n",
    "\n",
    "# Perform MCMC sampling\n",
    "samples, kernel_results = run_mcmc()\n",
    "\n",
    "# Posterior samples for each parameter\n",
    "a_samples, b_samples, w_samples, kappa_samples = samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "missing a required argument: 'loc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 40\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Instantiate model and call on data\u001b[39;00m\n\u001b[1;32m     39\u001b[0m model \u001b[38;5;241m=\u001b[39m VonMisesMixtureModel(T, K, P)\n\u001b[0;32m---> 40\u001b[0m log_likelihood \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Log-likelihood for given data\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Define optimizer and minimize negative log-likelihood\u001b[39;00m\n\u001b[1;32m     43\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam()\n",
      "Cell \u001b[0;32mIn[4], line 28\u001b[0m, in \u001b[0;36mVonMisesMixtureModel.__call__\u001b[0;34m(self, u)\u001b[0m\n\u001b[1;32m     25\u001b[0m class_probs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39msoftmax(eta)  \u001b[38;5;66;03m# Softmax for class probabilities\u001b[39;00m\n\u001b[1;32m     27\u001b[0m mu \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mmatmul(u, tf\u001b[38;5;241m.\u001b[39mexpand_dims(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))[:, \u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Mean direction\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m components \u001b[38;5;241m=\u001b[39m [tfd\u001b[38;5;241m.\u001b[39mVonMises(mu\u001b[38;5;241m=\u001b[39mmu, concentration\u001b[38;5;241m=\u001b[39mk) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkappa]\n\u001b[1;32m     30\u001b[0m mixture_dist \u001b[38;5;241m=\u001b[39m tfd\u001b[38;5;241m.\u001b[39mMixtureSameFamily(\n\u001b[1;32m     31\u001b[0m     mixture_distribution\u001b[38;5;241m=\u001b[39mtfd\u001b[38;5;241m.\u001b[39mCategorical(probs\u001b[38;5;241m=\u001b[39mclass_probs),\n\u001b[1;32m     32\u001b[0m     components_distribution\u001b[38;5;241m=\u001b[39mtfd\u001b[38;5;241m.\u001b[39mVonMises(\n\u001b[1;32m     33\u001b[0m         loc\u001b[38;5;241m=\u001b[39mmu, concentration\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkappa  \u001b[38;5;66;03m# von Mises components\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     )\n\u001b[1;32m     35\u001b[0m )\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mixture_dist\u001b[38;5;241m.\u001b[39mlog_prob(y)\n",
      "Cell \u001b[0;32mIn[4], line 28\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     25\u001b[0m class_probs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39msoftmax(eta)  \u001b[38;5;66;03m# Softmax for class probabilities\u001b[39;00m\n\u001b[1;32m     27\u001b[0m mu \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mmatmul(u, tf\u001b[38;5;241m.\u001b[39mexpand_dims(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))[:, \u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Mean direction\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m components \u001b[38;5;241m=\u001b[39m [\u001b[43mtfd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVonMises\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcentration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkappa]\n\u001b[1;32m     30\u001b[0m mixture_dist \u001b[38;5;241m=\u001b[39m tfd\u001b[38;5;241m.\u001b[39mMixtureSameFamily(\n\u001b[1;32m     31\u001b[0m     mixture_distribution\u001b[38;5;241m=\u001b[39mtfd\u001b[38;5;241m.\u001b[39mCategorical(probs\u001b[38;5;241m=\u001b[39mclass_probs),\n\u001b[1;32m     32\u001b[0m     components_distribution\u001b[38;5;241m=\u001b[39mtfd\u001b[38;5;241m.\u001b[39mVonMises(\n\u001b[1;32m     33\u001b[0m         loc\u001b[38;5;241m=\u001b[39mmu, concentration\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkappa  \u001b[38;5;66;03m# von Mises components\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     )\n\u001b[1;32m     35\u001b[0m )\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mixture_dist\u001b[38;5;241m.\u001b[39mlog_prob(y)\n",
      "File \u001b[0;32m~/miniconda3/envs/ssm/lib/python3.10/site-packages/decorator.py:231\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfun\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[0;32m--> 231\u001b[0m         args, kw \u001b[38;5;241m=\u001b[39m \u001b[43mfix\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m caller(func, \u001b[38;5;241m*\u001b[39m(extras \u001b[38;5;241m+\u001b[39m args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[0;32m~/miniconda3/envs/ssm/lib/python3.10/site-packages/decorator.py:203\u001b[0m, in \u001b[0;36mfix\u001b[0;34m(args, kwargs, sig)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfix\u001b[39m(args, kwargs, sig):\n\u001b[1;32m    200\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;124;03m    Fix args and kwargs to be consistent with the signature\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 203\u001b[0m     ba \u001b[38;5;241m=\u001b[39m \u001b[43msig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m     ba\u001b[38;5;241m.\u001b[39mapply_defaults()  \u001b[38;5;66;03m# needed for test_dan_schult\u001b[39;00m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ba\u001b[38;5;241m.\u001b[39margs, ba\u001b[38;5;241m.\u001b[39mkwargs\n",
      "File \u001b[0;32m~/miniconda3/envs/ssm/lib/python3.10/inspect.py:3186\u001b[0m, in \u001b[0;36mSignature.bind\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3181\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   3182\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get a BoundArguments object, that maps the passed `args`\u001b[39;00m\n\u001b[1;32m   3183\u001b[0m \u001b[38;5;124;03m    and `kwargs` to the function's signature.  Raises `TypeError`\u001b[39;00m\n\u001b[1;32m   3184\u001b[0m \u001b[38;5;124;03m    if the passed arguments can not be bound.\u001b[39;00m\n\u001b[1;32m   3185\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ssm/lib/python3.10/inspect.py:3101\u001b[0m, in \u001b[0;36mSignature._bind\u001b[0;34m(self, args, kwargs, partial)\u001b[0m\n\u001b[1;32m   3099\u001b[0m                 msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmissing a required argument: \u001b[39m\u001b[38;5;132;01m{arg!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   3100\u001b[0m                 msg \u001b[38;5;241m=\u001b[39m msg\u001b[38;5;241m.\u001b[39mformat(arg\u001b[38;5;241m=\u001b[39mparam\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m-> 3101\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3102\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3103\u001b[0m     \u001b[38;5;66;03m# We have a positional argument to process\u001b[39;00m\n\u001b[1;32m   3104\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: missing a required argument: 'loc'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "# Dummy data placeholders\n",
    "T, K, P = 100, 3, 2  # example values for number of observations, classes, and input variables\n",
    "u = tf.random.normal([T, P])\n",
    "y = tf.random.uniform([T], minval=-tf.constant(np.pi), maxval=tf.constant(np.pi))\n",
    "\n",
    "tfd = tfp.distributions\n",
    "\n",
    "class VonMisesMixtureModel(tf.Module):\n",
    "    def __init__(self, T, K, P):\n",
    "        self.T = T\n",
    "        self.K = K\n",
    "        self.P = P\n",
    "\n",
    "        # Parameters\n",
    "        self.a = tf.Variable(tf.zeros([K]), name=\"a\")\n",
    "        self.b = tf.Variable(tf.zeros([K, P]), name=\"b\")\n",
    "        self.w = tf.Variable(tf.zeros([P]), name=\"w\")\n",
    "        self.kappa = tf.Variable(tf.ones([K]), name=\"kappa\")\n",
    "\n",
    "    def __call__(self, u):\n",
    "        eta = tf.linalg.matmul(u, self.b, transpose_b=True) + self.a  # Linear predictors\n",
    "        class_probs = tf.nn.softmax(eta)  # Softmax for class probabilities\n",
    "        \n",
    "        mu = tf.linalg.matmul(u, tf.expand_dims(self.w, -1))[:, 0]  # Mean direction\n",
    "        components = [tfd.VonMises(mu=mu, concentration=k) for k in self.kappa]\n",
    "        \n",
    "        mixture_dist = tfd.MixtureSameFamily(\n",
    "            mixture_distribution=tfd.Categorical(probs=class_probs),\n",
    "            components_distribution=tfd.VonMises(\n",
    "                loc=mu, concentration=self.kappa  # von Mises components\n",
    "            )\n",
    "        )\n",
    "        return mixture_dist.log_prob(y)\n",
    "\n",
    "# Instantiate model and call on data\n",
    "model = VonMisesMixtureModel(T, K, P)\n",
    "log_likelihood = model(u)  # Log-likelihood for given data\n",
    "\n",
    "# Define optimizer and minimize negative log-likelihood\n",
    "optimizer = tf.optimizers.Adam()\n",
    "for step in range(1000):  # Training loop\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = -tf.reduce_mean(log_likelihood)  # Negative log-likelihood\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
