{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "// Stan model for a Hidden Markov Model (HMM) with input-driven emission probabilities\n",
    "\n",
    "data {\n",
    "    int<lower=1> K;             // Number of hidden states (categories)\n",
    "    int<lower=1> V;             // Number of possible emissions (observations)\n",
    "    int<lower=1> T;             // Length of the observation sequence\n",
    "    int<lower=1, upper=V> w[T]; // Observed emissions at each time step (1-based indexing)\n",
    "    matrix[T, 2] X;             // Input features influencing emissions (T x 2 matrix)\n",
    "    vector<lower=0>[K] alpha;   // Dirichlet prior parameters for transition probabilities\n",
    "}\n",
    "parameters {\n",
    "    simplex[K] theta[K];                      // Transition probability matrix (K x K), each row sums to 1\n",
    "    matrix[3, V] phi_coeffs[K];               // Emission coefficients for each state (K x 3 x V)\n",
    "                                              // Each state has a matrix of coefficients:\n",
    "                                              // Rows represent intercept and coefficients for two features\n",
    "                                              // Columns represent the V possible emissions\n",
    "}\n",
    "model {\n",
    "    // \n",
    "    \n",
    "    Priors for the parameters\n",
    "    for (k in 1:K) {\n",
    "        theta[k] ~ dirichlet(alpha);                  // Each row of transition probabilities has a Dirichlet prior\n",
    "        to_vector(phi_coeffs[k]) ~ normal(0, 1);      // Emission coefficients have a normal prior\n",
    "    }\n",
    "    \n",
    "    // Hidden states (latent variables) and likelihood\n",
    "    {\n",
    "        int z[T];                                       // Hidden state sequence (latent states)\n",
    "        z[1] = categorical_rng(rep_vector(1.0 / K, K)); // Initialize the first state randomly with equal probability\n",
    "        \n",
    "        for (t in 1:T) {\n",
    "            vector[V] linear_pred;                    // Linear predictor for emission probabilities\n",
    "            \n",
    "            // Compute the linear predictor for each possible emission\n",
    "            for (v in 1:V) {\n",
    "                // For each emission 'v', compute:\n",
    "                // linear_pred[v] = intercept + feature1_coef * X[t, 1] + feature2_coef * X[t, 2]\n",
    "                linear_pred[v] = phi_coeffs[z[t], 1, v]               // Intercept term for current state and emission\n",
    "                                + X[t, 1] * phi_coeffs[z[t], 2, v]    // Coefficient for first input feature\n",
    "                                + X[t, 2] * phi_coeffs[z[t], 3, v];   // Coefficient for second input feature\n",
    "            }\n",
    "            \n",
    "            // Apply softmax to get emission probabilities that sum to 1\n",
    "            vector[V] emit_probs = softmax(linear_pred);\n",
    "            \n",
    "            // Observe emission 'w[t]' given the emission probabilities\n",
    "            w[t] ~ categorical(emit_probs);\n",
    "            \n",
    "            // State transition for next time step (except for the last time step)\n",
    "            if (t < T)\n",
    "                z[t + 1] ~ categorical(theta[z[t]]); // Transition to next state based on current state\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model {\n",
    "    // \n",
    "    \n",
    "    // Priors\n",
    "    a ~ normal(0, 5);                 // Prior for intercepts\n",
    "    b ~ normal(0, 5);                 // Prior for slopes\n",
    "    for (k in 1:K) {\n",
    "        phi[k] ~ dirichlet(rep_vector(1.0, V)); // Prior for emission probabilities\n",
    "    }\n",
    "\n",
    "    // Likelihood\n",
    "    for (t in 1:T) {\n",
    "        // Compute linear predictor for each class\n",
    "        vector[K] eta;\n",
    "        for (k in 1:K) {\n",
    "            eta[k] = a[k] + b[k] * u[t]; // Linear predictor for class k\n",
    "        }\n",
    "        // Convert to class probabilities using softmax\n",
    "        vector[K] class_probs = softmax(eta);\n",
    "\n",
    "        // Mixture likelihood\n",
    "        real llik = 0;\n",
    "        for (k in 1:K) {\n",
    "            llik += class_probs[k] * phi[k][y[t]]; // Probability of y[t] given class k\n",
    "        }\n",
    "        target += log(llik); // Increment log-likelihood\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Stan model for a regression mixture model with von Mises emissions\n",
    "// where latent class probabilities depend on inputs via logistic regression\n",
    "\n",
    "data {\n",
    "    int<lower=1> T;                     // Number of observations/time points\n",
    "    int<lower=1> K;                     // Number of latent classes\n",
    "    int<lower=1> P;                     // Number of input variables (covariates)\n",
    "    matrix[T, P] u;                     // Input variables (T x P matrix)\n",
    "    vector[T] y;                        // Observed outputs (angles in radians)\n",
    "}\n",
    "\n",
    "parameters {\n",
    "    vector[K] a;                        // Intercepts for class probabilities\n",
    "    matrix[K, P] b;                     // Coefficients for class probabilities (K x P)\n",
    "    vector[P] w;                        // Coefficients for mean direction (P x 1)\n",
    "    vector<lower=0>[K] kappa;           // Concentration parameters for von Mises (length K)\n",
    "}\n",
    "\n",
    "model {\n",
    "    //\n",
    "    \n",
    "    // Priors\n",
    "    a ~ normal(0, 5);                   // Prior for intercepts\n",
    "    to_vector(b) ~ normal(0, 5);        // Prior for slopes\n",
    "    w ~ normal(0, 5);                   // Prior for mean direction coefficients\n",
    "    kappa ~ gamma(2, 0.1);              // Prior for concentration parameters\n",
    "\n",
    "    // Likelihood\n",
    "    for (t in 1:T) {\n",
    "        // Compute linear predictor for class probabilities\n",
    "        vector[K] eta;\n",
    "        for (k in 1:K) {\n",
    "            eta[k] = a[k] + b[k] * u[t]'; // Linear predictor for class k\n",
    "        }\n",
    "        // Convert to class probabilities using softmax\n",
    "        vector[K] class_probs = softmax(eta);\n",
    "\n",
    "        // Compute mean direction for von Mises distribution\n",
    "        real mu = w' * u[t]'; // Mean direction depends on u_t and w\n",
    "\n",
    "        // Compute log mixture likelihood using log-sum-exp trick\n",
    "        vector[K] log_component;\n",
    "        for (k in 1:K) {\n",
    "            log_component[k] = log(class_probs[k]) + von_mises_lpdf(y[t] | mu, kappa[k]);\n",
    "        }\n",
    "        target += log_sum_exp(log_component); // Increment log-likelihood\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
